{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse vs dense vector comparison for retrieval:\n",
    "\n",
    "1. Install Okareo's Python SDK: &nbsp;&nbsp;  `pip install okareo`  &nbsp;&nbsp; \n",
    "\n",
    "2. Get your API token from [https://app.okareo.com/](https://app.okareo.com/).  \n",
    "   (Note: You will need to register first.)\n",
    "\n",
    "3. Go directly to the API settings by clicking the button under **\"1. Create API Token\"**. You can skip all other steps.\n",
    "\n",
    "4. Add your generated API token to the cell below. ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OKAREO_API_KEY = \"<YOUR-API-KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install okareo\n",
    "%pip install chromadb\n",
    "%pip install pandas\n",
    "%pip install torch\n",
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create vector database with SPLADE embeddings. This can take around 3 to 7 minutes depending on the device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import hashlib\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "class MyEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        model_id = 'naver/splade-cocondenser-ensembledistil'\n",
    "        mx = 0\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        model = AutoModelForMaskedLM.from_pretrained(model_id)\n",
    "        all_embeds = []\n",
    "        for doc in input:\n",
    "            tokens = tokenizer(doc, return_tensors='pt')\n",
    "            output = model(**tokens)\n",
    "            vec = torch.max(\n",
    "                torch.log(\n",
    "                    1 + torch.relu(output.logits)\n",
    "                ) * tokens.attention_mask.unsqueeze(-1),\n",
    "            dim=1)[0].squeeze()\n",
    "            cols = vec.nonzero().squeeze().cpu().tolist()\n",
    "\n",
    "            weights = vec[cols].cpu().tolist()\n",
    "            embed_arr = [0] * 30000\n",
    "            for i in range(len(cols)):\n",
    "                embed_arr[cols[i]] = weights[i]\n",
    "                if cols[i] > mx:\n",
    "                    mx = cols[i]\n",
    "            all_embeds.append(embed_arr)\n",
    "        return all_embeds\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"./splade/\")\n",
    "\n",
    "collection = chroma_client.create_collection(name=\"chromadb\", metadata={\"hnsw:space\": \"cosine\"}, embedding_function=MyEmbeddingFunction())\n",
    "# To run this cell again after embedding documents, comment out the line above and uncomment out the line below.\n",
    "# collection = chroma_client.get_collection(name=\"chromadb\", embedding_function=MyEmbeddingFunction())\n",
    "# If you would like to re-embed the doucments, delete the splade folder and restart the notebook\n",
    "df = pd.read_csv('ms_marco_dev.csv')\n",
    "\n",
    "rowsToEncode = 2000\n",
    "passages = df['finalpassage'].tolist()[:rowsToEncode]\n",
    "queries = df['query'].tolist()[:rowsToEncode]\n",
    "ids = []\n",
    "for i in df['query'].tolist():\n",
    "    ids.append(hashlib.md5(i.encode()).hexdigest())\n",
    "\n",
    "# Comment out the next 5 lines when you have already embedded the documents\n",
    "for i in range(0, math.floor(rowsToEncode / 50)):\n",
    "    collection.add(\n",
    "        documents=df['finalpassage'].tolist()[i*50:(i + 1)*50],\n",
    "        ids=ids[i*50:(i + 1)*50]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create scenario to test retrieval from the vector database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from okareo import Okareo\n",
    "from okareo_api_client.models import ScenarioSetCreate, ScenarioSetResponse, SeedData, ScenarioType\n",
    "\n",
    "okareo = Okareo(OKAREO_API_KEY)\n",
    "seed_data = []\n",
    "for i in range(0, rowsToEncode, 10):\n",
    "    seed_data.append(SeedData(input_=queries[i], result=[ids[i]]))\n",
    "scenario_set_create = ScenarioSetCreate(\n",
    "    name=\"Embedding scenarios\",\n",
    "    seed_data=seed_data,\n",
    ")\n",
    "scenario = okareo.create_scenario_set(scenario_set_create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the scenario against the SPLADE model and calcuate retrieval metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a test run using a scenario set loaded in the previous cell \n",
    "from datetime import datetime\n",
    "from okareo_api_client.models import TestRunType\n",
    "from okareo.model_under_test import CustomModel\n",
    "def query_results_to_score(results):\n",
    "    parsed_ids_with_scores = []\n",
    "    for i in range(0, len(results['distances'][0])):\n",
    "        score = (2 - results['distances'][0][i]) / 2 # this turns cosine distance into a 0 to 1 cosine similarity score\n",
    "        parsed_ids_with_scores.append((results['ids'][0][i], score))\n",
    "    return parsed_ids_with_scores\n",
    "\n",
    "class RetrievalModel(CustomModel):\n",
    "    def invoke(self, input: str):\n",
    "        results = collection.query(\n",
    "            query_texts=[input],\n",
    "            n_results=5\n",
    "        )\n",
    "        # return a tuple of (parsed_ids_with_scores, overall model response context)\n",
    "        return query_results_to_score(results), {'model_data': input} \n",
    "# this will return a model if it already exists or create a new one if it doesn't\n",
    "model_under_test = okareo.register_model(name=f\"splade {datetime.now().strftime('%m-%d %H:%M:%S')}\", model=RetrievalModel(name=\"splade\"))\n",
    "\n",
    "\n",
    "test_run_item = model_under_test.run_test(scenario=scenario, # use the scenario from the scenario set uploaded in the previous step\n",
    "                                          name=f\"Retrieval Test Run splade {datetime.now().strftime('%m-%d %H:%M:%S')}\", # name for test run\n",
    "                                          test_run_type=TestRunType.INFORMATION_RETRIEVAL,\n",
    "                                          calculate_metrics=True)\n",
    "\n",
    "# display model level metrics for the test run\n",
    "print(f\"See test run results: https://app.okareo.com/project/{test_run_item.project_id}/eval/{test_run_item.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load vector database with e5 embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        def average_pool(last_hidden_states: Tensor,\n",
    "                        attention_mask: Tensor) -> Tensor:\n",
    "            last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "            return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "        for i in range(len(input)):\n",
    "            input[i] = 'query: ' + (input[i] if isinstance(input[i], str) else '')\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-small-v2')\n",
    "        model = AutoModel.from_pretrained('intfloat/e5-small-v2')\n",
    "\n",
    "        # Tokenize the input texts\n",
    "        batch_dict = tokenizer(input, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "        outputs = model(**batch_dict)\n",
    "        embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "        return embeddings.tolist()\n",
    "chroma_client = chromadb.PersistentClient(path=\"./e5/\")\n",
    "\n",
    "collection = chroma_client.get_collection(name=\"chromadb\", embedding_function=MyEmbeddingFunction())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the scenario against the e5 model and calcuate retrieval metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalModel(CustomModel):\n",
    "    def invoke(self, input: str):\n",
    "        results = collection.query(\n",
    "            query_texts=[input],\n",
    "            n_results=5\n",
    "        )\n",
    "        # return a tuple of (parsed_ids_with_scores, overall model response context)\n",
    "        return query_results_to_score(results), {'model_data': input}\n",
    "\n",
    "# this will return a model if it already exists or create a new one if it doesn't\n",
    "model_under_test = okareo.register_model(name=\"e5\", model=RetrievalModel(name=\"e5 model\"))\n",
    "\n",
    "test_run_item = model_under_test.run_test(scenario=scenario, # use the scenario from the scenario set uploaded in the previous step\n",
    "                                          name=f\"Retrieval Test Run e5 {datetime.now().strftime('%m-%d %H:%M:%S')}\", # name for test run\n",
    "                                          test_run_type=TestRunType.INFORMATION_RETRIEVAL,\n",
    "                                          calculate_metrics=True)\n",
    "\n",
    "# display model level metrics for the test run\n",
    "print(f\"See test run results: {test_run_item.app_link}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
