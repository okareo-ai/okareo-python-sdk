{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/okareo-ai/okareo-python-sdk/blob/main/examples/test_runs.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "## Welcome to Okareo!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install okareo transformers torch matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data processing\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the JSONL string to a pandas DataFrame\n",
    "data = pd.read_json(path_or_buf=\"https://raw.githubusercontent.com/okareo-ai/okareo-python-sdk/origin/feature/classification-example-model/examples/webbizz_classification_questions.jsonl\", lines=True)\n",
    "\n",
    "# Convert the \"result\" column to numeric classes\n",
    "data[\"label\"] = data[\"result\"].map({\"complaints\": 2, \"returns\": 1, \"pricing\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefanbroecer/miniforge3/envs/okareo/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the DistilBERT model and tokenizer\n",
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", problem_type=\"multi_label_classification\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries for PyTorch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data = data.sample(frac=0.8)\n",
    "val_data = data.drop(train_data.index)\n",
    "\n",
    "# Create a custom dataset class for the text data\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx][\"input\"]\n",
    "        label = self.data.iloc[idx][\"label\"]\n",
    "\n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "        # Return the input IDs, attention mask, and label (reshape the input IDs and attention mask to remove an unneeded dimension)\n",
    "        return encoding.input_ids.squeeze(), encoding.attention_mask.squeeze(), label\n",
    "\n",
    "# Create Dataset objects for the training and validation sets\n",
    "train_data = TextDataset(train_data, tokenizer)\n",
    "val_data = TextDataset(val_data, tokenizer)\n",
    "\n",
    "# Create DataLoader objects for the training and validation sets\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An optimizer for the model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# One epoch of training\n",
    "def train(loader, model, optimizer):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    print(\"Training...\")\n",
    "    losses = []\n",
    "    for input_ids, attention_mask, labels in loader:\n",
    "        optimizer.zero_grad()\n",
    "        # One-hot encode the labels\n",
    "        oh_labels = torch.nn.functional.one_hot(labels, num_classes=3).to(torch.float32)\n",
    "        # Pass the input IDs, attention mask, and one-hot labels to the model and get the loss\n",
    "        loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=oh_labels).loss\n",
    "        # Backpropagate the loss\n",
    "        loss.backward()\n",
    "        # Update the model parameters\n",
    "        optimizer.step()\n",
    "        # Track losses\n",
    "        losses.append(loss.item())\n",
    "    return losses\n",
    "\n",
    "# One epoch of validation\n",
    "def validate(loader, model, epoch):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    print(\"Validating...\")\n",
    "    # Disable gradient calculations (not needed for validation)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for input_ids, attention_mask, labels in loader:\n",
    "            # Pass the input IDs and attention mask to the model and get the logits\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "            # Get the predicted labels\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            # Track accuracy\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += len(labels)\n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch {epoch}, Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model for 3 epochs\n",
    "for epoch in range(3):\n",
    "    # Train the model for one epoch\n",
    "    losses = train(train_loader, model, optimizer)\n",
    "    # Plot the loss\n",
    "    plt.plot(losses)\n",
    "    plt.title(f\"Epoch {epoch} Loss\")\n",
    "    plt.show()\n",
    "    # Validate the model\n",
    "    validate(val_loader, model, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"webbizz_classification_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushing to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"webbizz_classification_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 268M/268M [03:25<00:00, 1.30MB/s]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sbroecker/webbizz_classification_model/commit/067ac98727c00482984f4717dd0d8de5ea3989ee', commit_message='Upload DistilBertForSequenceClassification', commit_description='', oid='067ac98727c00482984f4717dd0d8de5ea3989ee', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to Hugging Face Hub\n",
    "model.push_to_hub(\"webbizz_classification_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
