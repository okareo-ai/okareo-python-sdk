{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/okareo-ai/okareo-python-sdk/blob/main/examples/generating_classification_scenarios.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "## Generate synthetic data to use in classification\n",
    "\n",
    "1. Install Okareo's Python SDK: &nbsp;&nbsp;  `pip install okareo`  &nbsp;&nbsp; \n",
    "\n",
    "2. Get your API token from [https://app.okareo.com/](https://app.okareo.com/).  \n",
    "   (Note: You will need to register first.)\n",
    "\n",
    "3. Go directly to the API settings by clicking the button under **\"1. Create API Token\"**. You can skip all other steps.\n",
    "\n",
    "4. Add your generated API token to the cell below. ðŸ‘‡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "OKAREO_API_KEY = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install okareo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates the data that is used to train the model in this notebook:\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/okareo-ai/okareo-python-sdk/blob/main/examples/classification_eval_training.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by manually creating a set of seed questions.\n",
    "\n",
    "Those seed questions are used to create a Scenario Set in Okareo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.okareo.com/project/57101004-ed10-4301-bc64-5576f2aa3513/scenario/c7e8b8b0-5954-4c9a-96d7-335ca00f7ecd\n"
     ]
    }
   ],
   "source": [
    "from okareo import Okareo\n",
    "import os\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "okareo = Okareo(OKAREO_API_KEY)\n",
    "\n",
    "# Start with sample data for complaints, returns, and pricing\n",
    "rows = [\n",
    "\t{\"input\": \"What are the current discounts available on electronic gadgets?\", \"result\": \"pricing\"},\n",
    "\t{\"input\": \"Are there any seasonal sales or upcoming promotions I should be aware of?\", \"result\": \"pricing\"},\n",
    "\t{\"input\": \"How can I apply a discount code to my purchase?\", \"result\": \"pricing\"},\n",
    "\t{\"input\": \"Is there a loyalty program that provides additional savings on purchases?\", \"result\": \"pricing\"},\n",
    "\t{\"input\": \"I'd like to purchase additional filters for my model, how much are they?\", \"result\": \"pricing\",},\n",
    "\t{\"input\": \"Do you offer any discounts or promotions?\", \"result\": \"pricing\"},\n",
    "\t{\"input\": \"Why was I charged more than the listed price at checkout?\", \"result\": \"pricing\"},\n",
    "\t{\"input\": \"I received a damaged item; how do I go about getting a replacement?\", \"result\": \"returns\"},\n",
    "\t{\"input\": \"Will I be refunded in full, or will there be deductions for restocking fees?\", \"result\": \"returns\"},\n",
    "\t{\"input\": \"I received a damaged item. What is the process for returning it?\", \"result\": \"returns\"},\n",
    "\t{\"input\": \"I accidentally ordered two of the same item. Can I return one?\", \"result\": \"returns\"},\n",
    "\t{\"input\": \"I want to exchange the product I bought for a different size. What's the process?\", \"result\": \"returns\"},\n",
    "\t{\"input\": \"I have an issue with the quality of Product Y; whom do I contact?\", \"result\": \"complaints\"},\n",
    "\t{\"input\": \"Where can I send feedback about a particular problematic order?\", \"result\": \"complaints\"},\n",
    "\t{\"input\": \"My product arrived late, and this has caused inconvenience; what can be done about this?\", \"result\": \"complaints\"},\n",
    "\t{\"input\": \"What is the escalation process for unresolved issues?\", \"result\": \"complaints\"},\n",
    "\t{\"input\": \"Can I speak directly to a manager about my ongoing issue?\", \"result\": \"complaints\"},\n",
    "\t{\"input\": \"I have some quality concerns with your product, who can I talk to?\", \"result\": \"complaints\"},\n",
    "\t{\"input\": \"The product I bought is not working as advertised. Who can I contact?\", \"result\": \"complaints\"},\n",
    "\t{\"input\": \"I was overcharged for my purchase. Who can help me with this?\", \"result\": \"complaints\"},\n",
    "\t{\"input\": \"The product I bought is of poor quality. Who can I report this to?\", \"result\": \"complaints\"},\n",
    "]\n",
    "\n",
    "temp_dir = tempfile.gettempdir()\n",
    "file_path = os.path.join(temp_dir, \"seed_data_sample.jsonl\")\n",
    "\n",
    "# Write to a .jsonl file\n",
    "with open(file_path, \"w+\") as file:\n",
    "    for row in rows:\n",
    "        file.write(json.dumps(row) + '\\n')\n",
    "    \n",
    "\n",
    "# Create scenario set with seed data file\n",
    "source_scenario = okareo.upload_scenario_set(file_path=file_path, scenario_name=\"Blog Test Set\")\n",
    "print(source_scenario.app_link)\n",
    "\n",
    "# make sure to clean up tmp file\n",
    "os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the seed Scenario Set, we create a new Scenario Set using Okareo's generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.okareo.com/project/57101004-ed10-4301-bc64-5576f2aa3513/scenario/1230ea78-4836-4c97-9ba4-05c4b47a3060\n"
     ]
    }
   ],
   "source": [
    "from okareo_api_client.models import ScenarioType\n",
    "# Use scenario set id or scenario set object from previous step as source for generation\n",
    "rephrased_scenario = okareo.generate_scenarios(\n",
    "    source_scenario=source_scenario,\n",
    "    name=\"Blog - rephrase\",\n",
    "    number_examples=3,\n",
    "    generation_type=ScenarioType.REPHRASE_INVARIANT\n",
    ")\n",
    "\n",
    "print(rephrased_scenario.app_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.okareo.com/project/57101004-ed10-4301-bc64-5576f2aa3513/scenario/dc5d0a94-2868-4081-b2c2-f0a0741c8f11\n"
     ]
    }
   ],
   "source": [
    "spelling_scenario = okareo.generate_scenarios(\n",
    "    source_scenario=source_scenario,\n",
    "    name=\"Blog - spelling\",\n",
    "    number_examples=3,\n",
    "    generation_type=ScenarioType.COMMON_MISSPELLINGS\n",
    ")\n",
    "\n",
    "print(spelling_scenario.app_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.okareo.com/project/57101004-ed10-4301-bc64-5576f2aa3513/scenario/c756017a-3765-4bfa-8625-0e98a1ac7b0c\n"
     ]
    }
   ],
   "source": [
    "contr_scenario = okareo.generate_scenarios(\n",
    "    source_scenario=source_scenario,\n",
    "    name=\"Blog - contractions\",\n",
    "    number_examples=3,\n",
    "    generation_type=ScenarioType.COMMON_CONTRACTIONS\n",
    ")\n",
    "\n",
    "print(contr_scenario.app_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.okareo.com/project/57101004-ed10-4301-bc64-5576f2aa3513/scenario/074b2868-e446-40fc-b719-ec6faffce43a\n"
     ]
    }
   ],
   "source": [
    "cond_scenario = okareo.generate_scenarios(\n",
    "    source_scenario=source_scenario,\n",
    "    name=\"Blog - conditional\",\n",
    "    number_examples=3,\n",
    "    generation_type=ScenarioType.CONDITIONAL\n",
    ")\n",
    "\n",
    "print(cond_scenario.app_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefanbroecker/miniforge3/envs/nli/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load all of the necessary libraries from Okareo\n",
    "from okareo.model_under_test import CustomModel, ModelInvocation\n",
    "\n",
    "# Load the torch library\n",
    "import torch\n",
    "\n",
    "# Load libraries\n",
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# Load a tokenizer for the model from the Hugging Face Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Load Okareo's pretrained model from the Hugging Face Hub\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"blog_model_base\")\n",
    "\n",
    "# Create an instance of the Okareo client\n",
    "okareo = Okareo(OKAREO_API_KEY)\n",
    "\n",
    "# Define a model class that will be used used for classification\n",
    "# The model takes in a scenario and returns a predicted class\n",
    "class ClassificationModel(CustomModel):\n",
    "    # Constructor for the model\n",
    "    def __init__(self, name, tokenizer, model):\n",
    "        self.name = name\n",
    "        # The pretrained tokenizer\n",
    "        self.tokenizer = tokenizer\n",
    "        # The pretrained model\n",
    "        self.model = model\n",
    "        # The possible labels for the model\n",
    "        self.label_lookup = [\"pricing\", \"returns\", \"complaints\"]\n",
    "\n",
    "    # Callable to be applied to each scenario in the scenario set\n",
    "    def invoke(self, input: str):\n",
    "        # Tokenize the input\n",
    "        encoding = self.tokenizer(input, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "        # Get the logits from the model\n",
    "        logits = self.model(**encoding).logits\n",
    "        # Get the index of the highest value (the predicted class)\n",
    "        idx = torch.argmax(logits, dim=1).item()\n",
    "        # Get the label for the predicted class\n",
    "        prediction = self.label_lookup[idx]\n",
    "        \n",
    "        # Return the prediction in a ModelInvocation object\n",
    "        return ModelInvocation(\n",
    "                model_prediction=prediction,\n",
    "                model_input=input,\n",
    "                model_output_metadata={ \"prediction\": prediction, \"confidence\": logits.softmax(dim=1).max().item() },\n",
    "            )\n",
    "\n",
    "# Register the model with Okareo\n",
    "# This will return a model if it already exists or create a new one if it doesn't\n",
    "model_under_test_base = okareo.register_model(name=\"blog_intent_classifier_model_base\", model=ClassificationModel(name=\"Classification model\", tokenizer=tokenizer, model=model), update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run_item = model_under_test_base.run_test(\n",
    "    scenario=rephrased_scenario.scenario_id, \n",
    "    name=\"Blog - rephrase\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_base.run_test(\n",
    "    scenario=spelling_scenario.scenario_id, \n",
    "    name=\"Blog - spelling\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_base.run_test(\n",
    "    scenario=contr_scenario.scenario_id, \n",
    "    name=\"Blog - contractions\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_base.run_test(\n",
    "    scenario=cond_scenario.scenario_id, \n",
    "    name=\"Blog - conditional\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_base.run_test(\n",
    "    scenario=source_scenario.scenario_id, \n",
    "    name=\"Blog - base\", \n",
    "    calculate_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Okareo's pretrained model from the Hugging Face Hub\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"blog_model_synthetic\")\n",
    "\n",
    "# Create an instance of the Okareo client\n",
    "okareo = Okareo(OKAREO_API_KEY)\n",
    "\n",
    "# Define a model class that will be used used for classification\n",
    "# The model takes in a scenario and returns a predicted class\n",
    "class ClassificationModel(CustomModel):\n",
    "    # Constructor for the model\n",
    "    def __init__(self, name, tokenizer, model):\n",
    "        self.name = name\n",
    "        # The pretrained tokenizer\n",
    "        self.tokenizer = tokenizer\n",
    "        # The pretrained model\n",
    "        self.model = model\n",
    "        # The possible labels for the model\n",
    "        self.label_lookup = [\"pricing\", \"returns\", \"complaints\"]\n",
    "\n",
    "    # Callable to be applied to each scenario in the scenario set\n",
    "    def invoke(self, input: str):\n",
    "        # Tokenize the input\n",
    "        encoding = self.tokenizer(input, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "        # Get the logits from the model\n",
    "        logits = self.model(**encoding).logits\n",
    "        # Get the index of the highest value (the predicted class)\n",
    "        idx = torch.argmax(logits, dim=1).item()\n",
    "        # Get the label for the predicted class\n",
    "        prediction = self.label_lookup[idx]\n",
    "        \n",
    "        # Return the prediction in a ModelInvocation object\n",
    "        return ModelInvocation(\n",
    "                model_prediction=prediction,\n",
    "                model_input=input,\n",
    "                model_output_metadata={ \"prediction\": prediction, \"confidence\": logits.softmax(dim=1).max().item() },\n",
    "            )\n",
    "\n",
    "# Register the model with Okareo\n",
    "# This will return a model if it already exists or create a new one if it doesn't\n",
    "model_under_test_syn = okareo.register_model(name=\"blog_intent_classifier_model_w_synthetic\", model=ClassificationModel(name=\"Classification model\", tokenizer=tokenizer, model=model), update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run_item = model_under_test_syn.run_test(\n",
    "    scenario=rephrased_scenario.scenario_id, \n",
    "    name=\"Blog - syn - rephrase\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_syn.run_test(\n",
    "    scenario=spelling_scenario.scenario_id, \n",
    "    name=\"Blog - syn - spelling\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_syn.run_test(\n",
    "    scenario=contr_scenario.scenario_id, \n",
    "    name=\"Blog - syn - contractions\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_syn.run_test(\n",
    "    scenario=cond_scenario.scenario_id, \n",
    "    name=\"Blog - syn - conditional\", \n",
    "    calculate_metrics=True)\n",
    "\n",
    "test_run_item = model_under_test_syn.run_test(\n",
    "    scenario=source_scenario.scenario_id, \n",
    "    name=\"Blog - syn - base\", \n",
    "    calculate_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
