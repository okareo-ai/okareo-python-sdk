{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Finetuning of Intent Detection Model in Okareo\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/okareo-ai/okareo-python-sdk/blob/main/examples/classification_finetuning_eval_part1.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "Note: Since Jupyter notebooks need to be restarted to clear the CUDA cache, this notebook comes in two parts. Before running [Part #2](https://github.com/okareo-ai/okareo-python-sdk/blob/main/examples/classification_finetuning_eval_part2.ipynb), please run all the cells in this notebook then restart to clear the CUDA cache.\n",
    "\n",
    "## ðŸŽ¯ Goals\n",
    "\n",
    "After using this notebook, you will be able to:\n",
    "- Finetune an open source LLM for classification\n",
    "- Evaluate the finetuned model in Okareo\n",
    "- Generate synthetic data from misclassified points to augment the finetuning set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement: Intent Detection\n",
    "\n",
    "Suppose we are developing a RAG system that answers user questions about an online retailer called WebBizz. \n",
    "\n",
    "This notebook focuses on finetuning an open source LLM, [Phi-3-mini-4k-instruct](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct), for the Intent Detection component of the RAG pipeline.\n",
    "\n",
    "The purpose of Intent Detection is to determine which database to query during retrieval, which can help the RAG fetch relevant context chunks to improve the context of the generative model, improving downstream metrics like Consistency and reducing Hallucinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating User Questions from Documents\n",
    "\n",
    "We start by bootstraping our finetuning setup with synthetic user questions created with Okareo's scenario generators.\n",
    "\n",
    "First, we setup our Okareo client. You will need API token from [https://app.okareo.com/](https://app.okareo.com/). (Note: You will need to register first.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Okareo client\n",
    "\n",
    "import os\n",
    "from okareo import Okareo\n",
    "\n",
    "OKAREO_API_KEY = \"<YOUR_OKAREO_API_KEY>\"\n",
    "okareo = Okareo(OKAREO_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we download our WebBizz articles and read them into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  5515  100  5515    0     0  38264      0 --:--:-- --:--:-- --:--:-- 38298\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from io import StringIO \n",
    "\n",
    "# import chromadb\n",
    "import pandas as pd \n",
    "\n",
    "# We load 10 short summaries about different business aspects to the vector database.\n",
    "\n",
    "webbizz_articles = os.popen('curl https://raw.githubusercontent.com/okareo-ai/okareo-python-sdk/main/examples/webbizz_10_articles.jsonl').read()\n",
    "json_df = pd.read_json(path_or_buf=StringIO(webbizz_articles), lines=True)\n",
    "\n",
    "def label_article(val):\n",
    "    # assign different intent labels based on substring matching\n",
    "    if \"return\" in val:\n",
    "        return \"Returns\"\n",
    "    elif \"newsletter\" in val:\n",
    "        return \"Newsletter\"\n",
    "    elif \"sustainability\" in val:\n",
    "        return \"Sustainability\"\n",
    "    elif \"security\" in val:\n",
    "        return \"Safety\"\n",
    "    elif \"support\" in val or \"help\" in val:\n",
    "        return \"Support\"\n",
    "    elif \"member\" in val:\n",
    "        return \"Membership\"\n",
    "    else:\n",
    "        return \"Miscellaneous\"\n",
    "\n",
    "json_df['label'] = json_df['input'].apply(lambda x: label_article(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75eaa363-dfcc-499f-b2af-1407b43cb133</td>\n",
       "      <td>WebBizz is dedicated to providing our customer...</td>\n",
       "      <td>Support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ac0d464c-f673-44b8-8195-60c965e47525</td>\n",
       "      <td>Safety and security of your data is our top pr...</td>\n",
       "      <td>Safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aacf7a34-9d3a-4e2a-9a5c-91f2a0e8a12d</td>\n",
       "      <td>WebBizz places immense value on its dedicated ...</td>\n",
       "      <td>Membership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1a37b5e-58c4-4f5a-bc42-1b70253b8bf3</td>\n",
       "      <td>At WebBizz, we recognize that your shopping pr...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35a4fd5b-453e-4ca6-9536-f20db7303344</td>\n",
       "      <td>At WebBizz, we value our customer's feedback a...</td>\n",
       "      <td>Returns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f658c264-4a8a-4c93-a6d7-9a3d75f5a6f3</td>\n",
       "      <td>Are you facing hurdles with technical glitches...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a8a97b0e-8d9a-4a1c-b93e-83d2bc9e5266</td>\n",
       "      <td>Navigating WebBizz is a breeze with our advanc...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0b85c12f-6ea6-4d4a-85de-6c6e9a9f8c78</td>\n",
       "      <td>We're proud of our diverse product catalog tha...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cda67f1d-19f2-4b45-9f3e-3b8d67f8c6c5</td>\n",
       "      <td>Subscribing to our newsletter gives you a fron...</td>\n",
       "      <td>Newsletter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6e4f1c97-3f7a-4fcd-a4a3-69c9817c8fd1</td>\n",
       "      <td>WebBizz believes in sustainability. We've inte...</td>\n",
       "      <td>Sustainability</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 result  \\\n",
       "0  75eaa363-dfcc-499f-b2af-1407b43cb133   \n",
       "1  ac0d464c-f673-44b8-8195-60c965e47525   \n",
       "2  aacf7a34-9d3a-4e2a-9a5c-91f2a0e8a12d   \n",
       "3  f1a37b5e-58c4-4f5a-bc42-1b70253b8bf3   \n",
       "4  35a4fd5b-453e-4ca6-9536-f20db7303344   \n",
       "5  f658c264-4a8a-4c93-a6d7-9a3d75f5a6f3   \n",
       "6  a8a97b0e-8d9a-4a1c-b93e-83d2bc9e5266   \n",
       "7  0b85c12f-6ea6-4d4a-85de-6c6e9a9f8c78   \n",
       "8  cda67f1d-19f2-4b45-9f3e-3b8d67f8c6c5   \n",
       "9  6e4f1c97-3f7a-4fcd-a4a3-69c9817c8fd1   \n",
       "\n",
       "                                               input           label  \n",
       "0  WebBizz is dedicated to providing our customer...         Support  \n",
       "1  Safety and security of your data is our top pr...          Safety  \n",
       "2  WebBizz places immense value on its dedicated ...      Membership  \n",
       "3  At WebBizz, we recognize that your shopping pr...   Miscellaneous  \n",
       "4  At WebBizz, we value our customer's feedback a...         Returns  \n",
       "5  Are you facing hurdles with technical glitches...   Miscellaneous  \n",
       "6  Navigating WebBizz is a breeze with our advanc...   Miscellaneous  \n",
       "7  We're proud of our diverse product catalog tha...   Miscellaneous  \n",
       "8  Subscribing to our newsletter gives you a fron...      Newsletter  \n",
       "9  WebBizz believes in sustainability. We've inte...  Sustainability  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The name for a scenario must be unique. The scenario name WebBizz Documents (Seed) is already in use, and has been returned from this call.\n"
     ]
    }
   ],
   "source": [
    "from okareo_api_client.models.generation_tone import GenerationTone\n",
    "from okareo_api_client.models.scenario_set_create import ScenarioSetCreate\n",
    "from okareo_api_client.models.scenario_set_generate import ScenarioSetGenerate\n",
    "from okareo_api_client.models.scenario_type import ScenarioType\n",
    "from okareo_api_client.models.seed_data import SeedData\n",
    "\n",
    "# Create a scenario set of the WebBizz documents\n",
    "seed_data = []\n",
    "for article, label in zip(json_df['input'].to_list(), json_df['label'].to_list()):\n",
    "    seed_data.append(SeedData(input_=article, result=label))\n",
    "\n",
    "document_scenario = okareo.create_scenario_set(\n",
    "    ScenarioSetCreate(\n",
    "        name=f\"WebBizz Documents (Seed)\", seed_data=seed_data\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question scenario: https://app.okareo.com/project/89920a9a-54cc-40c8-af68-9975e64e8d18/scenario/9b0ed30a-155f-4bd3-90c3-154a40eecbfd\n",
      "rephrased scenario: https://app.okareo.com/project/89920a9a-54cc-40c8-af68-9975e64e8d18/scenario/85c1e499-e251-4071-a531-171e629580d0\n"
     ]
    }
   ],
   "source": [
    "# Use the scenario set of documents to generate a scenario of questions\n",
    "generated_scenario = okareo.generate_scenario_set(\n",
    "    ScenarioSetGenerate(\n",
    "        name=f\"Intent Detection - User Questions\",\n",
    "        source_scenario_id=document_scenario.scenario_id,\n",
    "        number_examples=5,\n",
    "        generation_type=ScenarioType.TEXT_REVERSE_QUESTION,\n",
    "        generation_tone=GenerationTone.INFORMAL\n",
    "    )\n",
    ")\n",
    "print(f\"question scenario: {generated_scenario.app_link}\")\n",
    "\n",
    "# Get more questions with the rephrasing generator\n",
    "rephrased_scenario = okareo.generate_scenario_set(\n",
    "    ScenarioSetGenerate(\n",
    "        name=f\"Intent Detection - Rephrased User Questions\",\n",
    "        source_scenario_id=generated_scenario.scenario_id,\n",
    "        number_examples=1,\n",
    "        generation_type=ScenarioType.REPHRASE_INVARIANT,\n",
    "        generation_tone=GenerationTone.INFORMAL\n",
    "    )\n",
    ")\n",
    "print(f\"rephrased scenario: {rephrased_scenario.app_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data for Instruction Finetuning\n",
    "\n",
    "Now we get the generated user questions, build train/test splits, and format the train split for instruction finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# get the generated questions\n",
    "data = {'input': [], 'label': []}\n",
    "for s in [generated_scenario, rephrased_scenario]:\n",
    "    sdp = okareo.get_scenario_data_points(s.scenario_id)\n",
    "    for sd in sdp:\n",
    "        data['input'].append(sd.input_)\n",
    "        data['label'].append(sd.result[0])\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What kind of products does WebBizz offer?</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does WebBizz ensure their collections are ...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are there any special deals or sales that WebB...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does WebBizz collaborate with designers for th...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What should I look out for if I want to catch ...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input          label\n",
       "0          What kind of products does WebBizz offer?  Miscellaneous\n",
       "1  How does WebBizz ensure their collections are ...  Miscellaneous\n",
       "2  Are there any special deals or sales that WebB...  Miscellaneous\n",
       "3  Does WebBizz collaborate with designers for th...  Miscellaneous\n",
       "4  What should I look out for if I want to catch ...  Miscellaneous"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scikit-learn's model_selection module to get class-balanced train/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train rows: 70\n",
      "# test rows: 30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Create a StratifiedShuffleSplit object\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "\n",
    "# Get the indices for the training and test sets\n",
    "for train_index, test_index in sss.split(df, df['label']):\n",
    "    train_df = df.loc[train_index].reset_index(drop=True)\n",
    "    test_df = df.loc[test_index].reset_index(drop=True)\n",
    "\n",
    "print(f\"# train rows: {train_df.shape[0]}\")\n",
    "print(f\"# test rows: {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I easily find a specific product on a ...</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What brands are supported by WebBizz?</td>\n",
       "      <td>Sustainability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is there a way to get personalized product rec...</td>\n",
       "      <td>Support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What should I do if I have questions about my ...</td>\n",
       "      <td>Support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can I sort products on an online store?</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input           label\n",
       "0  How can I easily find a specific product on a ...   Miscellaneous\n",
       "1              What brands are supported by WebBizz?  Sustainability\n",
       "2  Is there a way to get personalized product rec...         Support\n",
       "3  What should I do if I have questions about my ...         Support\n",
       "4        How can I sort products on an online store?   Miscellaneous"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: https://app.okareo.com/project/89920a9a-54cc-40c8-af68-9975e64e8d18/scenario/8368324d-e57e-46d5-b79c-0e1dfbe3b7f0\n",
      "test: https://app.okareo.com/project/89920a9a-54cc-40c8-af68-9975e64e8d18/scenario/4be1401d-c9fd-4691-90f0-21a1fa90ab72\n"
     ]
    }
   ],
   "source": [
    "# create scenarios with full json results\n",
    "scenario_ids = {}\n",
    "for name, split_df in zip(['train', 'test'], [train_df, test_df]):\n",
    "    scenario_set_create = ScenarioSetCreate(\n",
    "        name=f\"WebBizz Intent Detection - {name}\",\n",
    "        seed_data=[\n",
    "            SeedData(\n",
    "                input_=split_df.loc[i, 'input'],\n",
    "                result=split_df.loc[i, 'label']\n",
    "            ) for i in range(split_df.shape[0])\n",
    "        ] \n",
    "    )\n",
    "\n",
    "    split_scenario = okareo.create_scenario_set(scenario_set_create)\n",
    "    scenario_ids[name] = split_scenario.scenario_id\n",
    "\n",
    "    print(f'{name}: {split_scenario.app_link}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning instructions should be formatted with the following three fields:\n",
    "- Instruction: Description of the task, input/output format.\n",
    "- Input: Text used to prompt the LLM\n",
    "- Output: Expected response from the LLM\n",
    "\n",
    "We provide a template for our WebBizz intent detection task below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_PREAMBLE = \"\"\"### Instruction:\n",
    "Given \"Input\", return a category under \"Output\" that is one of the following:\n",
    "\n",
    "- Newsletter\n",
    "- Miscellaneous\n",
    "- Sustainability\n",
    "- Membership\n",
    "- Support\n",
    "- Safety\n",
    "- Returns\n",
    "\n",
    "Return only one category that is most relevant to the question.\n",
    "\"\"\"\n",
    "\n",
    "def format_instruction_for_scenario(input_name=\"{input}\"):\n",
    "\treturn f\"\"\"{PROMPT_PREAMBLE}\n",
    "### Input:\n",
    "{input_name}\n",
    " \n",
    "### Output:\n",
    "{{result}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Given \"Input\", return a category under \"Output\" that is one of the following:\n",
      "\n",
      "- Newsletter\n",
      "- Miscellaneous\n",
      "- Sustainability\n",
      "- Membership\n",
      "- Support\n",
      "- Safety\n",
      "- Returns\n",
      "\n",
      "Return only one category that is most relevant to the question.\n",
      "\n",
      "### Input:\n",
      "{input}\n",
      " \n",
      "### Output:\n",
      "{result}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "post_template = format_instruction_for_scenario(\"{input}\")\n",
    "print(post_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_instruction_data = [\n",
    "    post_template.format(\n",
    "        input=train_df.loc[i, 'input'],\n",
    "        result=train_df.loc[i, 'label']\n",
    "    ) for i in range(train_df.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Given \"Input\", return a category under \"Output\" that is one of the following:\n",
      "\n",
      "- Newsletter\n",
      "- Miscellaneous\n",
      "- Sustainability\n",
      "- Membership\n",
      "- Support\n",
      "- Safety\n",
      "- Returns\n",
      "\n",
      "Return only one category that is most relevant to the question.\n",
      "\n",
      "### Input:\n",
      "How can I easily find a specific product on a website?\n",
      " \n",
      "### Output:\n",
      "Miscellaneous\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(finetuning_instruction_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "p = [os.getcwd(), \"finetuning\", \"webbizz_finetuning_train_instructions.jsonl\" ] \n",
    "file_path = os.path.join(*p)\n",
    "\n",
    "with open(file_path, \"w\") as file:\n",
    "    for row in finetuning_instruction_data:\n",
    "        file.write(json.dumps({'sample': row}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mason/miniconda3/envs/phi3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 70 examples [00:00, 3246.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('json', data_files={'train': file_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Phi-3 for finetuning\n",
    "\n",
    "Now we set up a finetuning run using the finetuning instruction scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.07s/it]\n",
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing with max_seq_length=124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mason/miniconda3/envs/phi3/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, packing. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/mason/miniconda3/envs/phi3/lib/python3.11/site-packages/transformers/training_args.py:1960: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "/home/mason/miniconda3/envs/phi3/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:181: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/mason/miniconda3/envs/phi3/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/mason/miniconda3/envs/phi3/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "Generating train split: 58 examples [00:00, 2366.16 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from finetuning.utils import get_model_tokenizer_trainer\n",
    " \n",
    "# Microsoft's huggingface model id for Phi-3\n",
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "# directory where finetuned model weights will be written\n",
    "finetuned_model_name = \"Phi-3-mini-4k-int4\"\n",
    "\n",
    "# target modules for LoRA\n",
    "target_modules= ['k_proj', 'q_proj', 'v_proj', 'o_proj', \"gate_proj\", \"down_proj\", \"up_proj\"]\n",
    "\n",
    "# set up peft model/tokenizer/trainer for finetuning\n",
    "peft_model, tokenizer, trainer = get_model_tokenizer_trainer(\n",
    "    model_id,\n",
    "    finetuned_model_name,\n",
    "    dataset,\n",
    "    target_modules=target_modules,\n",
    "    epochs=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mason/miniconda3/envs/phi3/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n",
      "/home/mason/miniconda3/envs/phi3/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9538, 'grad_norm': 0.21841156482696533, 'learning_rate': 0.0005, 'epoch': 1.3333333333333333}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mason/miniconda3/envs/phi3/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4025, 'grad_norm': 0.1987246423959732, 'learning_rate': 0.0005, 'epoch': 2.6666666666666665}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mason/miniconda3/envs/phi3/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1285, 'grad_norm': 0.22796112298965454, 'learning_rate': 0.0005, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mason/miniconda3/envs/phi3/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 129.1121, 'train_samples_per_second': 2.246, 'train_steps_per_second': 0.271, 'train_loss': 0.439920711517334, 'epoch': 4.666666666666667}\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "trainer.train() # there will not be a progress bar since tqdm is disabled\n",
    " \n",
    "# save model\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the finetuned model in Okareo\n",
    "\n",
    "Now we will register the finetuned model in Okareo to perform classification evaluations on the train/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model + unpatching flash attention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.67s/it]\n",
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from finetuning.utils import get_finetuned_model_tokenizer\n",
    "\n",
    "# load the peft model with the base model\n",
    "finetuned_model_name = \"Phi-3-mini-4k-int4\"\n",
    "peft_model, tokenizer = get_finetuned_model_tokenizer(finetuned_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from okareo.model_under_test import CustomModel, ModelInvocation\n",
    "\n",
    "def format_instruction(sample):\n",
    "\tprompt = f\"\"\"{PROMPT_PREAMBLE}\n",
    "### Input:\n",
    "{sample['question']}\n",
    " \n",
    "### Output:\n",
    "\"\"\"\n",
    "\tif 'category' in sample.keys():\n",
    "\t\tprompt += f\"{sample['category']}\\n\"\n",
    "\treturn prompt\n",
    "\n",
    "mut_name = f\"WebBizz Intent Detection - Phi-3-mini-4k finetuned\"\n",
    "\n",
    "class FinetunedPhi3Model(CustomModel):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.model = peft_model\n",
    "        self.categories = [\n",
    "            \"Newsletter\",\n",
    "            \"Miscellaneous\",\n",
    "            \"Sustainability\",\n",
    "            \"Membership\",\n",
    "            \"Support\",\n",
    "            \"Safety\",\n",
    "            \"Returns\",\n",
    "        ]\n",
    "\n",
    "    def invoke(self, input_value):\n",
    "        prompt = format_instruction({ \"question\": input_value })\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "        outputs = self.model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_new_tokens=5,\n",
    "            do_sample=False,\n",
    "        )\n",
    "        pred = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):].strip()\n",
    "        res = \"Unknown\"\n",
    "        for cat in self.categories:\n",
    "            if cat in pred:\n",
    "                res = cat\n",
    "        return ModelInvocation(\n",
    "            model_prediction=res,\n",
    "            model_input=input_value,\n",
    "            raw_model_output=pred,\n",
    "        )\n",
    "\n",
    "# Register the model to use in the test run\n",
    "model_under_test = okareo.register_model(\n",
    "    name=mut_name,\n",
    "    model=[FinetunedPhi3Model(name=FinetunedPhi3Model.__name__)],\n",
    "    update=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split: See results in Okareo: https://app.okareo.com/project/89920a9a-54cc-40c8-af68-9975e64e8d18/eval/f2eabbfb-6d51-45f4-8862-71e1bda5e392\n",
      "test split: See results in Okareo: https://app.okareo.com/project/89920a9a-54cc-40c8-af68-9975e64e8d18/eval/7df3dcfb-e19f-4baf-9754-41cb3ac06814\n"
     ]
    }
   ],
   "source": [
    "from okareo_api_client.models.test_run_type import TestRunType\n",
    "\n",
    "for name in [\"train\", \"test\"]:\n",
    "    eval_name = f\"Intent Detection ({name}, no synthetic data)\"\n",
    "    evaluation = model_under_test.run_test(\n",
    "        name=eval_name,\n",
    "        scenario=scenario_ids[name],\n",
    "        test_run_type=TestRunType.MULTI_CLASS_CLASSIFICATION,\n",
    "        calculate_metrics=True,\n",
    "    )\n",
    "    print(f\"{name} split: See results in Okareo: {evaluation.app_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating more finetuning data from failure cases\n",
    "\n",
    "To improve the finetuned model's performance, we will generate synthetic data from the mis-classified rows in the \"train\" split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from okareo_api_client.models.find_test_data_point_payload import FindTestDataPointPayload\n",
    "\n",
    "# use the id from the train split evaluation run\n",
    "train_eval_id = \"f2eabbfb-6d51-45f4-8862-71e1bda5e392\"\n",
    "\n",
    "# get evaluation data\n",
    "eval_response = model_under_test.get_test_run(train_eval_id)\n",
    "\n",
    "# get scenario data points\n",
    "scenario_rows = okareo.get_scenario_data_points(eval_response.scenario_set_id)\n",
    "\n",
    "scenario_inputs = {}\n",
    "scenario_results = {}\n",
    "for row in scenario_rows:\n",
    "    scenario_inputs[row.id] = row.input_\n",
    "    scenario_results[row.id] = row.result\n",
    "\n",
    "# get test data points\n",
    "tdp = okareo.find_test_data_points(\n",
    "    FindTestDataPointPayload(\n",
    "        test_run_id=train_eval_id\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile scenario and test data points with relevant scores\n",
    "scenario_to_test_dp = {}\n",
    "for dp in tdp:\n",
    "    scenario_to_test_dp[dp.scenario_data_point_id] = {\n",
    "        'input': scenario_inputs[dp.scenario_data_point_id],\n",
    "        'expected': dp.metric_value.additional_properties['expected'],\n",
    "        'actual': dp.metric_value.additional_properties['actual'],\n",
    "        'test_data_point_id': dp.id,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the datapoints based on misclassified results\n",
    "filtered_dp = [dp for dp in scenario_to_test_dp.values() if dp['expected'] != dp['actual']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# write the failed rows\n",
    "file_path = \"./finetuning/webbizz_finetuning_train_failed_rows.jsonl\" \n",
    "with open(file_path, \"w\") as f:\n",
    "    for dp in filtered_dp:\n",
    "        json.dump({ \"input\": dp['input'], \"result\": dp['expected'] }, f)\n",
    "        f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_scenario_name = f\"WebBizz Intent Detection - train failures\"\n",
    "seed_scenario = okareo.upload_scenario_set(file_path=file_path, scenario_name=seed_scenario_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We utilize the same template from before, but this time we set it up for use with our scenario generator's `post_template` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Given \"Input\", return a category under \"Output\" that is one of the following:\n",
      "\n",
      "- Newsletter\n",
      "- Miscellaneous\n",
      "- Sustainability\n",
      "- Membership\n",
      "- Support\n",
      "- Safety\n",
      "- Returns\n",
      "\n",
      "Return only one category that is most relevant to the question.\n",
      "\n",
      "### Input:\n",
      "{generation.input}\n",
      " \n",
      "### Output:\n",
      "{result}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# format the scenario generation template to use the generator\n",
    "\n",
    "post_template_rephrase = format_instruction_for_scenario(\"{generation.input}\")\n",
    "print(post_template_rephrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from okareo_api_client.models.generation_tone import GenerationTone\n",
    "from okareo_api_client.models import ScenarioSetGenerate, ScenarioType\n",
    "\n",
    "# generate rephrased versions \n",
    "generate_scenario_name = f\"{seed_scenario_name} rephrased\"\n",
    "\n",
    "generate_request = ScenarioSetGenerate(\n",
    "    source_scenario_id=seed_scenario.scenario_id,\n",
    "    name=generate_scenario_name,\n",
    "    number_examples=3,\n",
    "    generation_type=ScenarioType.REPHRASE_INVARIANT,\n",
    "    generation_tone=GenerationTone.NEUTRAL,\n",
    "    post_template=post_template_rephrase\n",
    ")\n",
    "\n",
    "rephrased_instruction_scenario = okareo.generate_scenario_set(generate_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_scenario_id='8368324d-e57e-46d5-b79c-0e1dfbe3b7f0'\n",
      "test_scenario_id='4be1401d-c9fd-4691-90f0-21a1fa90ab72'\n",
      "rephrased_instruction_scenario_id='02148484-77a3-4909-8c52-0132ed2ab68c'\n"
     ]
    }
   ],
   "source": [
    "# copy the output of this cell into part 2 to continue finetuning with Okareo synthetic data\n",
    "print(f\"train_scenario_id='{scenario_ids['train']}'\")\n",
    "print(f\"test_scenario_id='{scenario_ids['test']}'\")\n",
    "print(f\"rephrased_instruction_scenario_id='{rephrased_instruction_scenario.scenario_id}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart the notebook to clear your CUDA cache, then continue on to Part 2!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phi3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
