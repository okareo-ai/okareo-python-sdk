{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/okareo-ai/okareo-python-sdk/blob/main/examples/classification_eval_with_OpenAI.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "## Classification template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "OKAREO_API_KEY = \"<YOUR-OKAREO-API-KEY>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which model should the classifier use?\n",
    "# We currently support OpenAI models and Cohere models.\n",
    "# If you have your own model, you can invoke it through our CustomModel class\n",
    "OPENAI_API_KEY = \"<YOUR-OPENAI-API-KEY>\"\n",
    "COHERE_API_KEY = \"<YOUR-COHERE-API-KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install okareo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using OpenAI, you can pass in a system prompt and a user prompt. These system prompt should explain what the system should do with the user prompt. The user prompt template allows you to customize the prompt for the \"user\" role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple adhoc classifier using OpenAI'a GPT 3.5 Turbo model\n",
    "# These prompts will be supplied to OpenAI\n",
    "USER_PROMPT_TEMPLATE = \"Lorem ipsum {input} Lorem ipsum\"\n",
    "\n",
    "CLASSIFICATION_CONTEXT_TEMPLATE = \"\"\"\n",
    "You will be provided a question from a customer.\n",
    "Classify the question into a customer category and sub-category.\n",
    "Provide the output with only the category name.\n",
    "\n",
    "Categories: Technical Support, Billing ...\n",
    "\n",
    "Sub-Categories for Technical Support:\n",
    "Troubleshooting\n",
    "...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see how a OpenAI, Cohere and Custom model is set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from okareo import Okareo\n",
    "# import OpenAIModel class to register the model\n",
    "from okareo.model_under_test import OpenAIModel, CohereModel, CustomModel\n",
    "\n",
    "okareo = Okareo(OKAREO_API_KEY)\n",
    "\n",
    "model_name = \"your-model-name\"\n",
    "\n",
    "# Register your model so it can be evaluated on a scenario set\n",
    "model_under_test = okareo.register_model(\n",
    "        # name=f\"AdHoc OpenAI Classifier - {random_string}\",\n",
    "        name=model_name,\n",
    "        model=OpenAIModel(\n",
    "            # Fill in the model id of your choosing, e.g. gpt-4-turbo-preview\n",
    "            model_id=\"gpt-3.5-turbo\",\n",
    "\n",
    "            # Add the temperature of the model\n",
    "            temperature=0, \n",
    "            system_prompt_template=CLASSIFICATION_CONTEXT_TEMPLATE,\n",
    "            user_prompt_template=USER_PROMPT_TEMPLATE,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "class CustomClassificationModel(CustomModel):\n",
    "    # Callable to be applied to each scenario in the scenario set\n",
    "    # You can add an endpoint to call your model or call your model directly\n",
    "    def invoke(self, input: str) -> tuple:\n",
    "        # call your model being tested here using <input> from the scenario set\n",
    "        if \"how much\" in input:\n",
    "            actual = \"pricing\"\n",
    "        elif \"return\" in input:\n",
    "            actual = \"returns\"\n",
    "        else:\n",
    "            actual = \"complaints\"\n",
    "\n",
    "        # return a tuple of (actual, overall model response context)\n",
    "        return actual, {\"labels\": actual, \"confidence\": .99 }  \n",
    "\n",
    "# this will return a model if it already exists or create a new one if it doesn't\n",
    "model_under_test = okareo.register_model(\n",
    "    name=model_name, \n",
    "    model=CustomClassificationModel(name=\"custom classification model\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a scenario to run the classifier on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.okareo.com/project/9255bce6-8704-42f7-8e8d-867f13cd9328/eval/30568c66-faf4-4ceb-902a-9ab04912a790\n"
     ]
    }
   ],
   "source": [
    "# Run the evaluation on the model and get a link to the results in Okareo\n",
    "\n",
    "from okareo import Okareo\n",
    "\n",
    "from okareo_api_client.models.test_run_type import TestRunType\n",
    "from okareo_api_client.models import ScenarioSetCreate, SeedData, ScenarioType\n",
    "\n",
    "\n",
    "# Generate example scenario based on seed data\n",
    "random_string = ''.join(random.choices(string.ascii_letters, k=5))\n",
    "scenario_set_create = ScenarioSetCreate(\n",
    "    name=f\"OpenAI AdHoc Category - {random_string}\",\n",
    "    number_examples=1,\n",
    "    generation_type=ScenarioType.SEED,\n",
    "    seed_data=[\n",
    "        SeedData(\n",
    "            input_=\"Can I connect my CRM?\",  \n",
    "            result=\"Technical Support\"\n",
    "        ),\n",
    "        SeedData(\n",
    "            input_=\"Do you have a way to send marketing emails?\",  \n",
    "            result=\"Technical Support\"\n",
    "        ),\n",
    "        SeedData(\n",
    "            input_=\"Can I get invoiced instead of using a credit card?\", \n",
    "            result=\"Billing\"\n",
    "        ),\n",
    "        SeedData(\n",
    "            input_=\"My CRM integration is not working.\", \n",
    "            result=\"Technical Support\"\n",
    "        ),\n",
    "        SeedData(\n",
    "            input_=\"Do you have SOC II tpye 2 certification?\", \n",
    "            result=\"Account Management\"\n",
    "        ),\n",
    "        SeedData(\n",
    "            input_=\"I like the product.  Please connect me to your enterprise team.\", \n",
    "            result=\"General Inquiry\"\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "scenario = okareo.create_scenario_set(scenario_set_create)\n",
    "\n",
    "# run the test and call the model for each item in the scenario set\n",
    "evaluation = model_under_test.run_test(\n",
    "        name=f\"adhoc-class-run-{random_string}\",\n",
    "        scenario=scenario,\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        test_run_type=TestRunType.MULTI_CLASS_CLASSIFICATION,\n",
    "        calculate_metrics=True,\n",
    "    )\n",
    "\n",
    "print(evaluation.app_link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
