{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/okareo-ai/okareo-python-sdk/blob/main/examples/classification_eval.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "## Welcome to Okareo!\n",
    "\n",
    "Get your API token from [https://app.okareo.com/](https://app.okareo.com/) and set it in the cell below. ðŸ‘‡\n",
    "   (Note: You will need to register first.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "OKAREO_API_KEY = \"<YOUR-OKAREO-API-TOKEN>\"\n",
    "\n",
    "%pip install okareo transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the first part of a RAG pipeline, we're going to set up a simple classification task that will score a model on how accurately it can classify different scenarios. The scenarios will be classified into three departments at WebBizz, an example web business. The setup will have three parts:\n",
    "\n",
    "1. A pretrained model that classifies scenarios as pertaining to either \"pricing,\" \"returns,\" or \"complaints\"\n",
    "2. A set of scenarios to test the model on\n",
    "3. An evaluation of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "\n",
    "The model is a finetuned version of [DistilBERT](https://huggingface.co/docs/transformers/en/model_doc/distilbert#distilbert), a smaller, faster version of BERT.\n",
    "\n",
    "Details on how the model was trained can be found in this notebook:\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/okareo-ai/okareo-python-sdk/blob/main/examples/classification_eval_training.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# Load a tokenizer for the model from the Hugging Face Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Load Okareo's pretrained model from the Hugging Face Hub\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"okareo-ai/webbizz_classification_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the necessary libraries from Okareo\n",
    "from okareo import Okareo\n",
    "from okareo_api_client.models import ScenarioSetCreate, SeedData\n",
    "from okareo.model_under_test import CustomModel, ModelInvocation\n",
    "\n",
    "# Load the torch library\n",
    "import torch\n",
    "\n",
    "# Create an instance of the Okareo client\n",
    "okareo = Okareo(OKAREO_API_KEY)\n",
    "\n",
    "# Define a model class that will be used used for classification\n",
    "# The model takes in a scenario and returns a predicted class\n",
    "class ClassificationModel(CustomModel):\n",
    "    # Constructor for the model\n",
    "    def __init__(self, name, tokenizer, model):\n",
    "        self.name = name\n",
    "        # The pretrained tokenizer\n",
    "        self.tokenizer = tokenizer\n",
    "        # The pretrained model\n",
    "        self.model = model\n",
    "        # The possible labels for the model\n",
    "        self.label_lookup = [\"pricing\", \"returns\", \"complaints\"]\n",
    "\n",
    "    # Callable to be applied to each scenario in the scenario set\n",
    "    def invoke(self, input: str):\n",
    "        # Tokenize the input\n",
    "        encoding = self.tokenizer(input, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "        # Get the logits from the model\n",
    "        logits = self.model(**encoding).logits\n",
    "        # Get the index of the highest value (the predicted class)\n",
    "        idx = torch.argmax(logits, dim=1).item()\n",
    "        # Get the label for the predicted class\n",
    "        prediction = self.label_lookup[idx]\n",
    "        \n",
    "        # Return the prediction in a ModelInvocation object\n",
    "        return ModelInvocation(\n",
    "                model_prediction=prediction,\n",
    "                model_input=input,\n",
    "                raw_model_output={ \"prediction\": prediction, \"confidence\": logits.softmax(dim=1).max().item() },\n",
    "            )\n",
    "\n",
    "# Register the model with Okareo\n",
    "# This will return a model if it already exists or create a new one if it doesn't\n",
    "model_under_test = okareo.register_model(name=\"intent_classifier_model\", model=ClassificationModel(name=\"Classification model\", tokenizer=tokenizer, model=model), update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The name for a scenario must be unique. The scenario name My Test Scenario Set is already in use, and has been returned from this call.\n"
     ]
    }
   ],
   "source": [
    "# Define a scenario set\n",
    "# This is a collection of scenarios that will be used to test the model\n",
    "scenario_set_create = ScenarioSetCreate(name=\"My Test Scenario Set\", # Name of the scenario set\n",
    "                                        # The data that will be used to test the model\n",
    "                                        # Each SeedData object has an input (the scenario) and a result (the expected output)\n",
    "                                        seed_data=[\n",
    "                                            SeedData(input_=\"I want to send this product back\", result=\"returns\"),\n",
    "                                            SeedData(input_=\"my product is not working\", result=\"complaints\"),\n",
    "                                            SeedData(input_=\"how much is the warranty on the product\", result=\"pricing\"),\n",
    "                                            SeedData(input_=\"this product is having issues\", result=\"complaints\"),\n",
    "                                            SeedData(input_=\"I want to send this product back for a return\", result=\"returns\"),\n",
    "                                            SeedData(input_=\"how much is this product\", result=\"pricing\"),\n",
    "                                            SeedData(input_=\"I just received my order, and it's not what I expected. What should I do?\", result=\"returns\"),\n",
    "                                            SeedData(input_=\"I ordered a book, but I received a DVD. What's the next step?\", result=\"returns\"),\n",
    "                                            SeedData(input_=\"I'm having trouble with the product I purchased. Who should I contact?\", result=\"complaints\"),\n",
    "                                            SeedData(input_=\"The software I purchased isn't compatible with my computer. Who can help me with this?\", result=\"complaints\"),\n",
    "                                            SeedData(input_=\"The product I bought last week is now on sale. Can I get a refund for the difference?\", result=\"pricing\"),\n",
    "                                            SeedData(input_=\"I saw an ad for a discount on your products, but I can't find any information on your site. Can you help?\", result=\"pricing\")])\n",
    "\n",
    "# Create the scenario set\n",
    "scenario = okareo.create_scenario_set(scenario_set_create)\n",
    "scenario_id = scenario.scenario_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See results in Okareo: http://localhost:3000/project/9f36c38b-31d6-4b34-a737-0237f24b8afb/eval/0b54377f-713d-4d21-9bc1-e415c875fc34\n"
     ]
    }
   ],
   "source": [
    "# Run the test\n",
    "# This will run the model on the scenarios in the scenario set\n",
    "test_run_item = model_under_test.run_test(scenario=scenario_id, name=\"Intent Classifier Run\", calculate_metrics=True)\n",
    "\n",
    "# Generate a link back to Okareo for evaluation visualization\n",
    "model_results = test_run_item.model_metrics.to_dict()\n",
    "app_link = test_run_item.app_link\n",
    "print(f\"See results in Okareo: {app_link}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
