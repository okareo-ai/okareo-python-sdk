{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/okareo-ai/okareo-python-sdk/blob/main/examples/embedding_comparison.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "## Optimizing Your RAG - Choose an Embedding Model That Fits Your Data\n",
    "\n",
    "Get your API token from [https://app.okareo.com/](https://app.okareo.com/) and set it in the cell below. ðŸ‘‡\n",
    "   (Note: You will need to register first.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "OKAREO_API_KEY = \"<YOUR-OKAREO-API-TOKEN>\"\n",
    "OPENAI_API_KEY = \"<YOUR-OPENAI-API-KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Okareo, ChromaDB, and pandas\n",
    "- Okareo will be used to evaluate and compare model performance\n",
    "- We will be using ChromaDB for query to document similarity search to compare embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install okareo\n",
    "%pip install chromadb\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Your RAG Questions\n",
    "- We are using a list of user questions with relevant document IDs to compare performance of different embedding models. Document IDs are pointing to documents that would be stored and retrieved by your RAG, usually from a vector database. This is our evaluation scenario.\n",
    "- Performance of similarity search of your RAG stack will depend on the types of data it stores and how it's being retrieved. The goal here is too see which embedding model does a better job of matching your type of user queries to your documents.\n",
    "- The example evaluation scenario below is based on fictitious WebBizz web business. WebBizz questions were created using [generate_retrieval_scenario.ipynb](https://github.com/okareo-ai/okareo-python-sdk/blob/main/examples/generate_retrieval_scenario.ipynb) notebook and downloaded from https://app.okareo.com/ as a .jsonl file.\n",
    "- You want to modify the [generate_retrieval_scenario.ipynb](https://github.com/okareo-ai/okareo-python-sdk/blob/main/examples/generate_retrieval_scenario.ipynb) notebook to generate a list of synthetic user questions based on your own documents, your own RAG data. You could then use it instead of example scenario below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from okareo import Okareo\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Create an instance of the Okareo client\n",
    "okareo = Okareo(OKAREO_API_KEY)\n",
    "random_string = ''.join(random.choices(string.ascii_letters, k=5))\n",
    "\n",
    "# Download questions from Okareo's GitHub repository\n",
    "webbizz_embedding_questions = os.popen('curl https://raw.githubusercontent.com/okareo-ai/okareo-python-sdk/main/examples/webbizz_embedding_questions.jsonl').read()\n",
    "\n",
    "with tempfile.NamedTemporaryFile(suffix=\"webbizz_embedding_questions.jsonl\", mode=\"w+\", delete=True) as temp_file:\n",
    "    temp_file.write(webbizz_embedding_questions)\n",
    "    temp_file.seek(0) # Move the file pointer to the beginning\n",
    "\n",
    "    # Upload the questions to Okareo from the temporary file\n",
    "    scenario = okareo.upload_scenario_set(file_path=temp_file.name, scenario_name=f\"RAG Embedding Comparison Questions - {random_string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Your Document Database\n",
    "- We will be loading WebBizz documents into ChromaDB. Below are different functions to help with loading and querying of documents from ChromaDB.\n",
    "- To compare performance we use different embedding models to encode the documents in DB and ecode the user questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import random\n",
    "import string\n",
    "from io import StringIO  \n",
    "import pandas as pd\n",
    "from okareo import Okareo\n",
    "from okareo.model_under_test import CustomModel, ModelInvocation\n",
    "\n",
    "# Create an instance of the Okareo client\n",
    "okareo = Okareo(OKAREO_API_KEY)\n",
    "random_string = ''.join(random.choices(string.ascii_letters, k=5))\n",
    "\n",
    "# Load documents from Okareo's GitHub repository\n",
    "webbizz_articles = os.popen('curl https://raw.githubusercontent.com/okareo-ai/okareo-python-sdk/main/examples/webbizz_30_articles.jsonl').read()\n",
    "\n",
    "# Convert the JSONL string to a pandas DataFrame\n",
    "jsonObj = pd.read_json(path_or_buf=StringIO(webbizz_articles), lines=True)\n",
    "\n",
    "# Create a ChromaDB client\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# A function to convert the query results from our ChromaDB collection into a list of dictionaries with the document ID, score, metadata, and label\n",
    "def query_results_to_score(results):\n",
    "    parsed_ids_with_scores = []\n",
    "    for i in range(0, len(results['distances'][0])):\n",
    "        # Create a score based on cosine similarity\n",
    "        score = (2 - results['distances'][0][i]) / 2\n",
    "        parsed_ids_with_scores.append(\n",
    "            {\n",
    "                \"id\": results['ids'][0][i],\n",
    "                \"score\": score,\n",
    "                \"metadata\": {'document' : results['documents'][0][i]},\n",
    "                \"label\": f\"WebBizz Article w/ ID: {results['ids'][0][i]}\"\n",
    "            }\n",
    "        )\n",
    "    return parsed_ids_with_scores\n",
    "\n",
    "# Implement Okareo CustomModel API that uses the ChromaDB collection to retrieve documents\n",
    "# This will return the top 5 most similar documents to the query based on embedding function and return these for evaluation\n",
    "class RetrievalModel(CustomModel):\n",
    "    def invoke(self, input: dict) -> ModelInvocation:\n",
    "        # Query the collection with the input text\n",
    "        results = collection.query(\n",
    "            query_texts=[input[\"question\"]],\n",
    "            n_results=5\n",
    "        )\n",
    "        # Return formatted query results and the model response context\n",
    "        return ModelInvocation(model_prediction=query_results_to_score(results), raw_model_output=results)\n",
    "\n",
    "def create_vector_collection(embedding_model_name, embedding_function):\n",
    "    # Create a ChromaDB collection\n",
    "    # The collection will be used to store the documents as vector embeddings\n",
    "    # We want to measure the similarity between questions and documents using cosine similarity \n",
    "    collection = chroma_client.get_or_create_collection(name=embedding_model_name + \"-comparison\", \n",
    "                                             metadata={\"hnsw:space\": \"cosine\"}, \n",
    "                                             embedding_function=embedding_function)\n",
    "\n",
    "    # Add the documents to the collection with the corresponding metadata\n",
    "    collection.add(\n",
    "        documents=list(jsonObj.input),\n",
    "        ids=list(jsonObj.result),\n",
    "    )\n",
    "\n",
    "    # Register the model being evaluated with Okareo\n",
    "    # This will return a model if it already exists or create a new one if it doesn't\n",
    "    model_under_test = okareo.register_model(name=embedding_model_name, model=RetrievalModel(name=embedding_model_name))\n",
    "    return model_under_test, collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance of **all-MiniLM-L6-v2** embedding model from SentenceTransformers\n",
    "- Model Card: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from okareo_api_client.models import TestRunType\n",
    "\n",
    "embedding_model_name = \"all-MiniLM-L6-v2\"\n",
    "# This is the default SentenceTransformer model that ChromaDB uses to embed the documents\n",
    "default_sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "model_under_test, collection = create_vector_collection(embedding_model_name, default_sentence_transformer_ef)\n",
    "\n",
    "# Perform a test run using the uploaded scenario \n",
    "test_run_item = model_under_test.run_test(\n",
    "    scenario=scenario, # use the scenario uploaded earlier in this notebook\n",
    "    name=f\"RAG Comparison {embedding_model_name} - {random_string}\", \n",
    "    test_run_type=TestRunType.INFORMATION_RETRIEVAL, # specify that we are running a retrieval test\n",
    ")\n",
    "\n",
    "# Print a link back to Okareo app for evaluation visualization\n",
    "print(f\"See results in Okareo app for embedding model {embedding_model_name}: {test_run_item.app_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance of **text-embedding-3-large** embedding model from OpenAI\n",
    "- Model Card: https://openai.com/index/new-embedding-models-and-api-updates/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from okareo_api_client.models import TestRunType\n",
    "\n",
    "embedding_model_name = \"text-embedding-3-large\"\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(api_key=OPENAI_API_KEY, model_name=embedding_model_name)\n",
    "model_under_test, collection = create_vector_collection(embedding_model_name, openai_ef)\n",
    "\n",
    "# Perform a test run using the uploaded scenario \n",
    "test_run_item = model_under_test.run_test(\n",
    "    scenario=scenario, # use the scenario uploaded earlier in this notebook\n",
    "    name=f\"RAG Comparison {embedding_model_name} - {random_string}\", \n",
    "    test_run_type=TestRunType.INFORMATION_RETRIEVAL, # specify that we are running a retrieval test\n",
    ")\n",
    "\n",
    "# Print a link back to Okareo app for evaluation visualization\n",
    "print(f\"See results in Okareo app for embedding model {embedding_model_name}: {test_run_item.app_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance of **gte-small** embedding model from Alibaba DAMO Academy\n",
    "- Model Card: https://huggingface.co/thenlper/gte-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from okareo_api_client.models import TestRunType\n",
    "\n",
    "embedding_model_name = \"thenlper/gte-small\"\n",
    "gte_small_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=embedding_model_name)\n",
    "model_under_test, collection = create_vector_collection(\"gte-small\", gte_small_ef)\n",
    "\n",
    "# Perform a test run using the uploaded scenario \n",
    "test_run_item = model_under_test.run_test(\n",
    "    scenario=scenario, # use the scenario uploaded earlier in this notebook\n",
    "    name=f\"RAG Comparison {embedding_model_name} - {random_string}\", \n",
    "    test_run_type=TestRunType.INFORMATION_RETRIEVAL, # specify that we are running a retrieval test\n",
    ")\n",
    "\n",
    "# Print a link back to Okareo app for evaluation visualization\n",
    "print(f\"See results in Okareo app for embedding model {embedding_model_name}: {test_run_item.app_link}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
