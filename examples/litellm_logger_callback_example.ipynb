{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/okareo-ai/okareo-python-sdk/blob/main/examples/classification_eval_with_OpenAI.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "## Log Example With LiteLLM:\n",
    "\n",
    "1. Install Okareo's Python SDK: &nbsp;&nbsp;  `pip install okareo`  &nbsp;&nbsp;\n",
    "\n",
    "2. Get your API token from [https://app.okareo.com/](https://app.okareo.com/).  \n",
    "   (Note: You will need to register first.)\n",
    "\n",
    "3. Go directly to the API settings by clicking the button under **\"1. Create API Token\"**. You can skip all other steps.\n",
    "\n",
    "4. Add your generated API token to the cell below. ðŸ‘‡\n",
    "\n",
    "5. Add your OpenAI key.  OpenAI is only needed for example purposes.  If you have your own model, you can substitute those in it's place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install okareo\n",
    "%pip install openai\n",
    "%pip install litellm\n",
    "\n",
    "OKAREO_API_KEY = \"<YOUR-OKAREO-API-KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import string\n",
    "from litellm import completion\n",
    "import litellm\n",
    "from okareo.litellm_logger import LiteLLMLoggerOpenAI \n",
    "\n",
    "random_string = ''.join(random.choices(string.ascii_letters, k=5))\n",
    "\n",
    "\n",
    "callobj = LiteLLMLoggerOpenAI(\n",
    "    api_key=OKAREO_API_KEY,\n",
    "    mut_name=\"LiteLLMLoggerOpenAI-Example-\"+random_string,\n",
    "    context_token=random_string,\n",
    "    tags=[\"litellm_logger_message\"]\n",
    ")\n",
    "\n",
    "#Please note running this notebook cell mulitlple times will create \n",
    "# addtional callbacks and duplicate datapoings being generated for each LLM call\n",
    "litellm.callbacks = [callobj]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{ \"content\": \"who is Obama?\",\"role\": \"user\"}]\n",
    "\n",
    "response = completion(\n",
    "  model=\"gpt-3.5-turbo\", \n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "\n",
    "print(response)\n",
    "print(\"Visit https://app.okareo.com/ to see your datapionts\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
