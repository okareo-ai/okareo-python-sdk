diff --git a/examples/test_runs.ipynb b/examples/test_runs.ipynb
index 2a4d4a6..0fe211e 100644
--- a/examples/test_runs.ipynb
+++ b/examples/test_runs.ipynb
@@ -34,15 +34,16 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "{'weighted_average': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.0}, 'scores_by_label': {'complains': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'complaints': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'pricing': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'returns': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}}\n",
-      "https://app.okareo.com/project/f7bfcff0-2b8d-4fec-ab20-51669cd3e732/eval/c7ed5146-f4d0-49e8-8420-c308f6228729\n"
+      "{'weighted_average': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5555555555555555, 'accuracy': 0.6666666666666666}, 'scores_by_label': {'pricing': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'complaints': {'precision': 0.5, 'recall': 1.0, 'f1': 0.6666666666666666}, 'returns': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}}\n",
+      "https://app.okareo.com/project/21b8a05b-f5b6-4578-a36a-fc264036d9d3/eval/d18fe542-2fb4-42c7-91a1-83cfeb83578d\n"
      ]
     }
    ],
    "source": [
-    "# perform a test run using a scenario set from one of the scenario_set notebook examples\n",
+    "# perform a test run using a scenario set\n",
     "import os\n",
     "from okareo import Okareo\n",
+    "from okareo_api_client.models import ScenarioSetCreate, SeedData, ScenarioType\n",
     "from okareo.model_under_test import CustomModel\n",
     "from types import SimpleNamespace\n",
     "\n",
@@ -54,8 +55,8 @@
     "    def invoke(self, input: str):\n",
     "        # call your model being tested here using <input> from the scenario set\n",
     "\n",
-    "        # mock code returnign a random label\n",
-    "        labels = [\"returns\", \"complains\", \"pricing\"]\n",
+    "        # mock code returning a random label\n",
+    "        labels = [\"returns\", \"complaints\", \"pricing\"]\n",
     "        import random\n",
     "        actual = random.choice(labels)\n",
     "\n",
@@ -64,8 +65,19 @@
     "# this will return a model if it already exists or create a new one if it doesn't\n",
     "model_under_test = okareo.register_model(name=\"intent_classifier\", model=RetrievalModel(name=\"custom classification\"))\n",
     "\n",
-    "# use the scenario id from one of the scenario set notebook examples\n",
-    "test_run_item = model_under_test.run_test(scenario='47cc9b5b-524b-4f7f-8a34-c1757be44ec0', name=\"Intent Classifier Run 3\", calculate_metrics=True)\n",
+    "# generate example scenario based on seed data and return results in one call\n",
+    "scenario_set_create = ScenarioSetCreate(name=\"My Test Scenario Set \",\n",
+    "                                        generation_type=ScenarioType.SEED,\n",
+    "                                        number_examples=1,\n",
+    "                                        seed_data=[SeedData(input_=\"I want to send this product back\", result=\"returns\"),\n",
+    "                                                   SeedData(input_=\"my product is not working\", result=\"complaints\"),\n",
+    "                                                   SeedData(input_=\"how much is this product?\", result=\"pricing\")])\n",
+    "\n",
+    "source_scenario = okareo.create_scenario_set(scenario_set_create)\n",
+    "scenario_id = source_scenario.scenario_id\n",
+    "\n",
+    "# use the scenario id to run the test\n",
+    "test_run_item = model_under_test.run_test(scenario=scenario_id, name=\"Intent Classifier Run 3\", calculate_metrics=True)\n",
     "\n",
     "# display model level metrics for the test run\n",
     "print(test_run_item.model_metrics.to_dict())\n",
@@ -81,8 +93,8 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "{'weighted_average': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.0}, 'scores_by_label': {'complains': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'complaints': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'pricing': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'returns': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}}}\n",
-      "https://app.okareo.com/project/f7bfcff0-2b8d-4fec-ab20-51669cd3e732/eval/c7ed5146-f4d0-49e8-8420-c308f6228729\n"
+      "{'weighted_average': {'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5555555555555555, 'accuracy': 0.6666666666666666}, 'scores_by_label': {'pricing': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}, 'complaints': {'precision': 0.5, 'recall': 1.0, 'f1': 0.6666666666666666}, 'returns': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0}}}\n",
+      "https://app.okareo.com/project/21b8a05b-f5b6-4578-a36a-fc264036d9d3/eval/d18fe542-2fb4-42c7-91a1-83cfeb83578d\n"
      ]
     }
    ],
@@ -121,7 +133,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.11.2"
+   "version": "3.11.5"
   }
  },
  "nbformat": 4,
